{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class Question(BaseModel):\n",
    "    topic: str = Field(description=\"Topic of the questions that has been generated\")\n",
    "    question: str = Field(description=\"Interview question for the candidate\")\n",
    "    answer: str = Field(description=\"Suggested answer for the question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"State management for the index graph.\"\"\"\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Annotated, Optional\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from shared.state import reduce_docs\n",
    "from shared.configuration import BaseConfiguration\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, TypedDict, List, Dict, Union, Annotated\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "\n",
    "    resume: str = field(\n",
    "        metadata={\n",
    "            \"description\": \"The resume of the candidate.\"\n",
    "        }\n",
    "    )\n",
    "    job_description: str = field(\n",
    "        metadata={\n",
    "            \"description\": \"The job description for the role, represented as a string.\"\n",
    "        }\n",
    "    )\n",
    "    job_title: str = field(\n",
    "        metadata={\n",
    "            \"description\": \"The job title for which questions and evaluations are generated.\"\n",
    "        }\n",
    "    )\n",
    "    company_name: str = field(\n",
    "        metadata={\n",
    "            \"description\": \"The name of the company associated with the job description.\"\n",
    "        }\n",
    "    )\n",
    "    history: Optional[List[Dict[str, str]]] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"description\": \"History of previously asked questions and answers as a list of dictionaries.\"\n",
    "        }\n",
    "    )\n",
    "    agent_out: Union[AgentAction, AgentFinish, None] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"description\": \"The output from the agent, which can be an action or a finish signal.\"\n",
    "        }\n",
    "    )\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\n",
    "            \"description\": \"A list of intermediate steps taken by the agent, each represented as a tuple of action and description.\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reachere here\n",
      "Error: Error code: 401 - {'statusCode': 401, 'message': 'Access denied due to invalid subscription key. Make sure to provide a valid key for an active subscription.'}\n",
      "{'resume': \"John Doe's resume text here...\", 'job_description': 'Job description for a data scientist role...', 'job_title': 'Data Scientist', 'company_name': 'Tech Corp', 'history': [{'question': 'What are your strengths?', 'answer': 'Problem-solving and teamwork'}], 'agent_out': \"Could not generate questions. Details: Error code: 401 - {'statusCode': 401, 'message': 'Access denied due to invalid subscription key. Make sure to provide a valid key for an active subscription.'}\", 'intermediate_steps': []}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This \"graph\" simply exposes an endpoint for a user to upload docs to be indexed.\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Optional\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langsmith import Client\n",
    "from dotenv import load_dotenv\n",
    "from shared.state import reduce_docs\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "from http.client import HTTPException\n",
    "import itertools\n",
    "import random\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "import certifi\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.chat_models import ChatAnyscale, BedrockChat\n",
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "import os\n",
    "from urllib3.util import parse_url\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Client()\n",
    "\n",
    "model = AzureChatOpenAI(temperature=0,\n",
    "                            seed=42,\n",
    "                            streaming=True,\n",
    "                            azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "                            openai_api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "                            openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "                            deployment_name=os.getenv('AZURE_OPENAI_CHATGPT_DEPLOYMENT'),\n",
    "                            openai_api_type=os.getenv('OPENAI_API_TYPE')\n",
    "                            )\n",
    "def generate_questions(state: list): \n",
    "    \"\"\"Generate interview questions using an LLM.\n",
    "    Args:\n",
    "        state (dict): The input state containing required fields.\n",
    "    Returns:\n",
    "        dict: A dictionary containing generated questions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"reachere here\")\n",
    "        # Ensure the state contains all required fields\n",
    "        required_fields = [\"resume\", \"job_description\", \"job_title\", \"company_name\", \"history\"]\n",
    "        for field in required_fields:\n",
    "            if field not in state:\n",
    "                raise ValueError(f\"Missing required field: {field}\")\n",
    "\n",
    "        document_prompt = client.pull_prompt(\"interviewer_prompt\")\n",
    "        chain = (document_prompt | model.with_structured_output(Question))\n",
    "        response = chain.invoke({\n",
    "            \"resume\": state[\"resume\"], \n",
    "            \"job_description\": state[\"job_description\"],\n",
    "            \"job_title\": state[\"job_title\"],\n",
    "            \"company_name\": state[\"company_name\"],\n",
    "            \"history\": state[\"history\"]\n",
    "        }) \n",
    "\n",
    "        print(response)\n",
    "        \n",
    "        return {\"agent_out\": response}\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return {\"agent_out\": f\"Could not generate questions. Details: {str(e)}\"}\n",
    "@tool\n",
    "def evaluate_answers(state: AgentState):\n",
    "    \"\"\"Generate interview questions using an LLM.\n",
    "    Args:\n",
    "        resume (str): The candidate's resume.\n",
    "        job_description (str): The job description for the role.\n",
    "        job_title (str): The job title of the role\n",
    "        company_name (str): The name of the company\n",
    "        history Optional[str]: History of previously asked questions and answers\n",
    "    Returns:\n",
    "        dict: A dictionary containing generated questions categorized into technical, personal, HR, and logical sections.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document_prompt = client.pull_prompt(\"quiz_from_jd\")\n",
    "        chain = (document_prompt | model.with_structured_output(Question))\n",
    "        response = chain.invoke({\"resume_text\": state.resume, \n",
    "                           \"job_description\": state.job_description,\n",
    "                           \"job_title\": state.job_title,\n",
    "                           \"company_name\": state.company_name,\n",
    "                           \"history\": state.history})\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return {\"error\": f\"Could not generate questions. Details: {str(e)}\"}\n",
    "@tool\n",
    "   \n",
    "def evaluate_candidate(state: AgentState):\n",
    "    \"\"\"Generate interview questions using an LLM.\n",
    "    Args:\n",
    "        resume (str): The candidate's resume.\n",
    "        job_description (str): The job description for the role.\n",
    "        job_title (str): The job title of the role\n",
    "        company_name (str): The name of the company\n",
    "        history Optional[str]: History of previously asked questions and answers\n",
    "    Returns:\n",
    "        dict: A dictionary containing generated questions categorized into technical, personal, HR, and logical sections.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document_prompt = client.pull_prompt(\"quiz_from_jd\")\n",
    "        chain = (document_prompt | model.with_structured_output(Question))\n",
    "        response = chain.invoke({\"resume_text\": state.resume, \n",
    "                           \"job_description\": state.job_description,\n",
    "                           \"job_title\": state.job_title,\n",
    "                           \"company_name\": state.company_name,\n",
    "                           \"history\": state.history})\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return {\"error\": f\"Could not generate questions. Details: {str(e)}\"}\n",
    "    \n",
    "def count_questions(state: AgentState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(generate_questions)\n",
    "builder.add_node(evaluate_answers)\n",
    "builder.add_edge(START, \"generate_questions\")\n",
    "#builder.add_edge(\"generate_questions\", \"evaluate_answers\")\n",
    "#builder.add_edge(\"evaluate_answers\", \"generate_questions\")\n",
    "builder.add_edge(\"generate_questions\", END)\n",
    "# Compile into a graph object that you can invoke and deploy.\n",
    "graph = builder.compile()\n",
    "graph.name = \"IndexGraph\"\n",
    "\n",
    "\n",
    "agent_state = AgentState(\n",
    "    resume=\"John Doe's resume text here...\",\n",
    "    job_description=\"Job description for a data scientist role...\",\n",
    "    job_title=\"Data Scientist\",\n",
    "    company_name=\"Tech Corp\",\n",
    "    history=[{\"question\": \"What are your strengths?\", \"answer\": \"Problem-solving and teamwork\"}]\n",
    ")\n",
    "\n",
    "result = graph.invoke({\n",
    "    \"resume\": \"John Doe's resume text here...\",\n",
    "    \"job_description\": \"Job description for a data scientist role...\",\n",
    "    \"job_title\": \"Data Scientist\",\n",
    "    \"company_name\": \"Tech Corp\",\n",
    "    \"history\": [{\"question\": \"What are your strengths?\", \"answer\": \"Problem-solving and teamwork\"}]\n",
    "})\n",
    "agent_state[\"history\"].append({\"question\": \"What is your experience with Python?\", \"answer\": \"5 years\"})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
